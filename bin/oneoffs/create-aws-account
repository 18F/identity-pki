#!/bin/bash

# Sets up the basic groundwork (via Terraform) for an AWS account.
# Must be run as an actual IAM user (vs. with an assumed role)
# with the AdministrativeAccess IAM policy attached.

set -euo pipefail

BASEPATH="$(dirname "$0")/.."
. "${BASEPATH}/lib/common.sh"
. "${BASEPATH}/lib/sandbox-lib.sh"
. "${BASEPATH}/lib/acct-lib.sh"

howto() { echo "Usage: ${0} [-potbs12345] [-a SRC_ACCT] IAM_USER_PROFILE_NAME" ; }
usage() { echo -e "\n$(howto)\nUse -h for more info!\n" ; }
help_me() {
  cat >&2 << EOM

$(howto)

Runs all necessary tasks to set up the basic infrastructure (in terraform/all)
for a (new) AWS account, including assumable IAM roles and the AWS account alias.

Some secrets and parameters are copied from a separate account, \`login-SRC_ACCT\`,
as they cannot be created/managed within the codebase/Terraform code.
Defaults to 'sandbox', can be otherwise set with the -a flag if desired
(i.e. \`-a prod\` to pull from the \`login-prod\` account instead.)

MUST be run as an IAM user (/not/ an assumed role)
within said account, which has the AdministrativeAccess IAM policy attached,
identified in ~/.aws/config as \`IAM_USER_PROFILE_NAME\` (required argument).

The tasks in this script can also be individually executed as follows:

  -p, -1 : Creates the 'RDSDeletionPrevent' and 'RegionRestriction' IAM policies,
           which are attached to all assumable IAM roles and required for
           subsequent 'terraform apply' operations to work properly,
           and the login-secrets S3 bucket for the account.
           (Step: 1_policies_secrets_buckets)
  -t, -2 : Import the 'terraform_locks' DynamoDB table -- created by ${BASEPATH}/tf-deploy
           during its first run -- into Terraform state, so that it can be managed
           directly in code.
           (Step: 2_import_lock_table)
  -b, -3 : Runs 'terraform apply' in the account as the Terraform role, creating all
           remaining resources defined in the terraform/all directory.
           (Step: 3_build_acct)
  -s, -4 : Copies the /account/slack/webhook/url SSM parameter from login-SRC_ACCT
           to each region, allowing Terraform to send notifications to Slack
           (Step: 4_slack_webhook_ssm_params)
  -h     : Displays this help

EOM
}

# targeted deploy to create the custom policies and secrets buckets
# (all are needed for the second 'apply' to work properly)
1_policies_secrets_buckets() {
  ${BASEPATH}/tf-deploy -t "all/${TF_ACCT}" apply -auto-approve \
    -target='module.main.aws_iam_policy.rds_delete_prevent' \
    -target='module.main.aws_iam_policy.region_restriction' \
    -target='module.main.module.main_secrets_bucket.aws_s3_bucket.secrets' \
    -target='module.main.module.main_secrets_bucket_ue1.aws_s3_bucket.secrets'
}

# since configure_state_bucket.sh creates the DynamoDB table if it doesn't exist,
# import it into state so it can be managed within Terraform in subsequent runs
2_import_lock_table() {
  export AWS_PROFILE=${ADMIN_IAM_ROLE}
  ${BASEPATH}/tf-deploy -t "all/${TF_ACCT}" import \
    'module.main.module.tf-state.aws_dynamodb_table.tf-lock-table[0]' 'terraform_locks'
}

# build the rest of terraform/all infra
3_build_acct() {
  export AWS_PROFILE=${ADMIN_IAM_ROLE}
  ${BASEPATH}/tf-deploy -t "all/${TF_ACCT}" apply -auto-approve \
    -var "splunk_oncall_cloudwatch_endpoint=${SPLUNK_CLOUDWATCH_ENDPOINT}"
    -var "splunk_oncall_newrelic_endpoint=${SPLUNK_NEWRELIC_ENDPOINT}"
}

# update the SSM slackwebhook parameters
4_slack_webhook_ssm_params() {
  local WEBHOOK_URL
  for REGION in 'us-west-2' 'us-east-1' ; do
    switch_creds source
    WEBHOOK_URL=$(printf "$(${BASEPATH}/awsv -x ${AV_PROFILE} aws ssm get-parameters \
                  --names '/account/slack/webhook/url' \
                  --region "${REGION}" \
                  --with-decryption | jq -r '.Parameters[].Value')")
    switch_creds dest
    ${BASEPATH}/awsv -x ${AV_PROFILE} aws ssm put-parameter \
      --name '/account/slack/webhook/url' \
      --value "${WEBHOOK_URL}" \
      --region "${REGION}" \
      --type SecureString \
      --description 'Slack webhook url for notifications' --overwrite
  done
}

# get SSM parameters from $SRC_ACCT and hold for later use
get_ssm_parameters_from_src_account() {
  SPLUNK_CLOUDWATCH_ENDPOINT=$(${BASEPATH}/awsv -x ${AV_PROFILE} \
      aws ssm get-parameter --with-decryption \
      --name /account/splunk_oncall/cloudwatch_endpoint | jq -r '.Parameter.Value'
  )
  SPLUNK_NEWRELIC_ENDPOINT=$(${BASEPATH}/awsv -x ${AV_PROFILE} \
      aws ssm get-parameter --with-decryption \
      --name /account/splunk_oncall/newrelic_endpoint | jq -r '.Parameter.Value'
  )
}

declare {TF_ACCT,ACCT_ID,SECRETS_BUCKET,ADMIN_IAM_ROLE,SPLUNK_NEWRELIC_ENDPOINT,SPLUNK_CLOUDWATCH_ENDPOINT}=
SRC_ACCT='sandbox'
verify_root_repo

TASKS=(
  "1_policies_secrets_buckets"
  "2_import_lock_table"
  "3_build_acct"
  "4_slack_webhook_ssm_params"
)
TODO=()

while getopts t1p2r3o4b5s6a:h opt
do
  case $opt in
    1|p) TODO+=("${TASKS[0]}") ;;
    2|t) TODO+=("${TASKS[2]}") ;;
    3|b) TODO+=("${TASKS[3]}") ;;
    4|s) TODO+=("${TASKS[4]}") ;;
    a) SRC_ACCT="${OPTARG}"    ;;
    h) help_me                 ;;
    *) usage && exit 1         ;;
  esac
done
shift $((OPTIND-1))

ADMIN_IAM_ROLE=${1-}
[[ -z ${ADMIN_IAM_ROLE} ]] && raise "Must provide an IAM profile name!"
export AWS_PROFILE=${ADMIN_IAM_ROLE}

verify_account_info
if [[ ! -z "${ACCOUNT_ALIAS}" ]] && [[ -z "${TODO-}" ]] ; then
  echo_red "Account alias '${ACCOUNT_ALIAS}' already exists for '${TF_ACCT}'."
  raise "Account may already exist; use bin/td for Terraform commands instead!"
fi

switch_creds source
get_ssm_parameters_from_src_account
switch_creds dest

run_tasks
